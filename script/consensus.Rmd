```{r}
library(here)
library(tibble)
library(dplyr)
library(data.table)
library(tidyr)
library(entropy)
library(qualvar)
```

```{r}
#Set working directory
setwd(here())
source("script/function.R")
```
```{r}
# Parameter
source("script/parameter.R")

```
```{r}
#set unknown 
#choose 1 if with unknown, 2 if w/o unknown
unknown <- unknowns[1]

#choose 1 if each, 2 if whole
#set whole vs each
run_each <- run_eachs[1]
```
```{r}
#choose what to analyse

pick <- 4
sig <- sigs[pick]
merge <- merges[pick]

#run_each <- run_eachs[2]
if (run_each) {
  run <- runs[1]
} else {
  run <- runs[2]
}



possible_cellstate <- all_cellstates[
  chosing[[pick]]
  ]

possible_cellstate_with_unknown <- c(possible_cellstate,"unknown")
possible_cellstate_with_unassign <- c(possible_cellstate,"unassign")
possible_cellstate_with_unassign_tie <- c(possible_cellstate,"unassign","tie")
possible_cellstate_with_tie <- c(possible_cellstate,"tie")
```



```{r}
### import all data
## marker.based
sc.type <- read.csv(paste0("output/scType_", object, "_", sig,"_",run, ".csv"), row.names = 1)
sc.type <- sc.type[,paste0("scType",unknown) ,drop = FALSE]

scina <- read.csv(paste0("output/SCINA_", object, "_", sig,"_",run, ".csv"), row.names = 1)
scina <- scina[,paste0("SCINA",unknown) ,drop = FALSE]


# # add full option
# sc.sorter <- read.csv(paste0("output/scsorter_", object, "_", sig, "_",run,".csv"), row.names = 1)
# sc.sorter$scSorter_no_unknown <- NA
# sc.sorter <- sc.sorter[,paste0("scSorter",unknown) ,drop = FALSE]
```


```{r}
#unknown <- unknowns[1]
# ref-based
clustify.r <- read.csv(paste0("output/clustifyr_", object, "_", merge, "_",run,".csv"), row.names = 1)
#clustify.r <- clustify.r[,paste0("clustifyr_ref",unknown) ,drop = FALSE]
clustify.r <- clustify.r[,paste0("clustifyr_ref") ,drop = FALSE]

scid <- read.csv(paste0("output/scID_", object, "_", merge,"_allassigned","_",run,".csv"), row.names = 1)
scid <- scid[,paste0("scID",unknown) ,drop = FALSE]
```


```{r}
# Add Full option
sc.pred <- read.csv(paste0("output/scpred_", object, "_", merge, "_",run, ".csv"), row.names = 1)
sc.pred <- sc.pred[,2:1]
colnames(sc.pred) <- c("scPred",paste0("scPred",unknowns[2]))
sc.pred <- sc.pred[,paste0("scPred",unknown) ,drop = FALSE]

single.r <- read.csv(paste0("output/singleR_", object, "_", merge, "_",run, ".csv"), row.names = 1)
single.r <- single.r[,2:1]
colnames(single.r) <- c("singleR",paste0("singleR",unknowns[2]))
single.r[is.na(single.r$singleR),"singleR"] <- "unknown"
single.r <- single.r[,paste0("singleR",unknown) ,drop = FALSE]

scibet <- read.csv(paste0("output/scibet_", object, "_", merge,  "_",run,".csv"), row.names = 1)
scibet$scibet_no_unknown <- scibet$scibet #no unknown by default
scibet <- scibet[,paste0("scibet",unknown) ,drop = FALSE]

chetah <- read.csv(paste0("output/CHETAH_", object, "_", merge, "_",run, ".csv"), row.names = 1)
chetah$CHETAH_no_unknown <- chetah$CHETAH
chetah <- chetah[,paste0("CHETAH",unknown) ,drop = FALSE]

scmap_cluster <- read.csv(paste0("output/scmap_cluster_", object, "_", merge,  "_",run,".csv"), row.names = 1)
scmap_cluster$scmap_cluster_no_unknown <- scmap_cluster$scmap_cluster #cannot tweak to have no unknown
scmap_cluster <- scmap_cluster[,paste0("scmap_cluster",unknown) ,drop = FALSE]

scmap_cell <- read.csv(paste0("output/scmap_cell_", object, "_", merge,  "_",run,".csv"), row.names = 1)
scmap_cell$scmap_cell_no_unknown <- scmap_cell$scmap_cell #cannot tweak to have no unknown
scmap_cell <- scmap_cell[,paste0("scmap_cell",unknown) ,drop = FALSE]
```

```{r}
#sc.type;scina; clustify.r;scid;sc.sorter;sc.pred;scibet;chetah;single.r;scmap_cluster;scmap_cluster
```


```{r}
anno <- bind_cols(sc.type, scina, clustify.r,scid)

#full option
#anno <- bind_cols(sc.type, scina, clustify.r,scid,sc.pred,scibet,chetah,single.r,scmap_cluster,scmap_cell)

#colnames(anno) <- paste(colnames(anno), sig, sep = "_")

anno[] <- lapply(anno, function(x) gsub("\\.new$", "like", x))
anno[] <- lapply(anno, function(x) gsub("Unknown", "unknown", x))
anno[] <- lapply(anno, function(x) gsub("unassigned", "unknown", x))
```

```{r}
anno
```
```{r}
tool_names <- colnames(anno)
```




```{r}
# Do sankey
library(ggsankey)
library(ggplot2)


all.sankey <- anno
colnames(all.sankey) <- gsub("_no_unknown","",colnames(all.sankey))
df <- all.sankey %>%
  make_long(colnames(all.sankey))

# Chart 1
pl <- ggplot(df, aes(
  x = x,
  next_x = next_x,
  node = node,
  next_node = next_node,
  fill = factor(node),
  label = node
))
pl <- pl + geom_sankey(
  flow.alpha = 0.5,
  node.color = "black",
  show.legend = FALSE
)
pl <- pl + geom_sankey_label(size = 2, color = "black", fill = "white")
pl <- pl + theme_bw()
pl <- pl + theme(legend.position = "none")
pl <- pl + theme(
  axis.title = element_blank(),
  axis.text.y = element_blank(),
  axis.ticks = element_blank(),
  panel.grid = element_blank()
)

# pl <- pl + scale_fill_viridis_d(option = "inferno")
pl <- pl + labs(title = paste(object, sig,run, unknown,sep = "; "))
pl <- pl + labs(fill = "Nodes")
pl
```




# agreement analysis

#test  -->
<!-- ```{r} -->
<!-- tools <- c("tool1","tool2","tool3","tool4","tool5") -->
<!-- anno.test <- data.frame(matrix(ncol = length(tools),nrow =0)) -->
<!-- possible_cellstate_test <- c("a","b","c","d","e","f","g") -->
<!-- cellstate_test <- possible_cellstate_test[1:5] -->

<!-- colnames(anno.test) <- tools -->
<!-- anno.test[1,] <- c("a","a","a","a","a") -->
<!-- anno.test[2,] <- c("a","a","a","a","b") -->
<!-- anno.test[3,] <- c("a","a","a","b","b") -->
<!-- anno.test[4,] <- c("a","a","a","b","c") -->
<!-- anno.test[5,] <- c("a","a","b","b","c") -->
<!-- anno.test[6,] <- c("a","a","c","b","d") -->
<!-- anno.test[7,] <- c("a","c","d","b","e") -->



<!-- #Calculate frequency for each -->


<!-- anno.count.test <- anno.test -->
<!-- tool <- "tool" -->
<!-- cellstate <- "cellstate" -->
<!-- gathercols <- colnames(anno.count.test) -->



<!-- anno.count.test <- rownames_to_column(anno.count.test,var = "cellname") -->


<!-- anno.count.test <- gather(anno.count.test, tool, cellstate, gathercols) -->
<!-- anno.count.test$cellstate <- factor(anno.count.test$cellstate, levels = cellstate_test) -->

<!-- anno.count.test <- anno.count.test %>%  -->
<!--   group_by(cellname) %>% -->
<!--   count(cellstate, name = "count") %>% -->
<!--   complete(cellstate, fill = list(count = 0))  -->

<!-- anno.count.test <- spread(anno.count.test, cellstate, count) -->

<!-- anno.count.test[is.na(anno.count.test)] <- 0 -->


<!-- anno.count.test <- column_to_rownames(anno.count.test,var = "cellname") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- anno.test -->
<!-- anno.count.test -->
<!-- ``` -->




<!-- ```{r} -->
<!-- # 5 tools 5 cell states -->
<!-- anno.count.test -->
<!-- iqv <- c("DM" ,"MDA" ,"ADA" ,"VA" ,"HREL" ,"B") -->

<!-- #IQV -->
<!-- anno.agreement <- data.frame(matrix(nrow = nrow(anno.count.test),ncol = length(iqv))) -->
<!-- rownames(anno.agreement) <- rownames(anno.count.test) -->
<!-- colnames(anno.agreement) <- iqv -->


<!-- anno.agreement$DM <- apply(anno.count.test, 1, DM) -->
<!-- anno.agreement$MDA <- apply(anno.count.test, 1, MDA) -->
<!-- anno.agreement$ADA <- apply(anno.count.test, 1, ADA) -->
<!-- anno.agreement$VA <- apply(anno.count.test, 1, VA) -->
<!-- anno.agreement$HREL <- apply(anno.count.test, 1, HREL) -->
<!-- anno.agreement$B <- apply(anno.count.test, 1, B) -->


<!-- # 0 mean more consistence; 1 mean zero agreement -->

<!-- anno.agreement <- format(round(anno.agreement, 3), nsmall = 3) -->

<!-- for (i in 1:ncol(anno.agreement)) { -->
<!--   anno.agreement[,i] <- as.numeric(anno.agreement[,i]) -->
<!-- } -->
<!-- ``` -->







<!-- ```{r} -->
<!-- #Fleiss -->
<!-- ``` -->


<!-- ```{r} -->
<!-- anno.agreement -->
<!-- ``` -->




#agreement analysis


```{r}
library(data.table)

# Convert to data.table

anno.count <- setDT(rownames_to_column(anno,var = "cellname"))

tool_names <- setdiff(names(anno.count), "cellname")

anno.count[] <- lapply(seq_along(anno.count), function(i) {
   ifelse(anno.count[[i]] == "unknown", paste("unknown", i-1, sep = "_"), anno.count[[i]]) 
 })
# Melt the data.table to long format
anno_long <- melt(anno.count, id.vars = "cellname", variable.name = "tool", value.name = "cellstate")


anno.count <- dcast(anno_long, cellname ~ cellstate, fun.aggregate = length)

anno.count[is.na(anno.count)] <- 0

anno.count <- column_to_rownames(anno.count,var = "cellname")

rm(anno_long)




anno.agreement <- data.frame(matrix(nrow = nrow(anno.count),ncol = 0))
rownames(anno.agreement) <- rownames(anno.count)


anno.count
```



#IQV





```{r}


anno.agreement$DM <- apply(anno.count, 1, DM)
anno.agreement$MDA <- apply(anno.count, 1, MDA)
anno.agreement$ADA <- apply(anno.count, 1, ADA)
anno.agreement$VA <- apply(anno.count, 1, VA)
anno.agreement$HREL <- apply(anno.count, 1, HREL)
anno.agreement$B <- apply(anno.count, 1, B)


# 0 mean more consistence; 1 mean zero agreement

anno.agreement <- format(round(anno.agreement, 3), nsmall = 3)

for (i in 1:ncol(anno.agreement)) {
  anno.agreement[,i] <- as.numeric(anno.agreement[,i])
}

anno.agreement
```

#(archieve explore the iqv) -->
<!-- ```{r} -->
<!-- all.iqv <- anno.agreement -->
<!-- ``` -->


<!-- ```{r} -->
<!-- #Check the range of -->
<!-- unique(all.iqv[,1]) -->
<!-- test <- list() -->
<!-- for (i in 1:ncol(all.iqv)) { -->
<!--   test <- append(test,list(unique(all.iqv[,i]))) -->
<!-- } -->
<!-- test -->
<!-- ``` -->



<!-- ```{r} -->
<!-- library(GGally) -->
<!-- all.iqv %>% -->
<!--   ggpairs(progress = FALSE) + -->
<!--   theme_bw() -->
<!-- ``` -->

<!-- ```{r} -->

<!-- #calculate bin width -->


<!-- bin_num <- 10 -->

<!-- p1 <- ggplot(all.iqv, aes(x=DM)) + geom_histogram(bins =  bin_num) -->
<!-- p2 <- ggplot(all.iqv, aes(x=MDA)) + geom_histogram(bins =  bin_num) -->
<!-- p3 <- ggplot(all.iqv, aes(x=ADA)) + geom_histogram(bins =  bin_num) -->
<!-- p4 <- ggplot(all.iqv, aes(x=VA)) + geom_histogram(bins =  bin_num) -->
<!-- p5 <- ggplot(all.iqv, aes(x=HREL)) + geom_histogram(bins =  bin_num) -->
<!-- p6 <- ggplot(all.iqv, aes(x=B)) + geom_histogram(bins =  bin_num) -->

<!-- (p1 + p2 + p3) / (p4 + p5 + p6) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #color_by resolution -->
<!-- all.iqv.con <- data.frame() -->
<!-- all.iqv.con <- cbind(all.iqv,all.consensus) -->

<!-- p1 <- ggplot(all.iqv.con, aes(x=DM, fill = res_0.6)) + geom_histogram(bins = bin_num) -->
<!-- p1 -->
<!-- ``` -->


<!-- ```{r} -->
<!-- #Plot lolipop -->
<!-- all.iqv.freq <- data.frame() -->
<!-- for (i in 1:ncol(all.iqv)){ -->
<!--   all.iqv.freq.each <- data.frame(table(all.iqv[,i])) -->
<!--   all.iqv.freq.each <- cbind(all.iqv.freq.each, data.frame(method = rep(colnames(all.iqv)[i],nrow(all.iqv.freq.each)))) -->
<!--   all.iqv.freq <- rbind(all.iqv.freq,all.iqv.freq.each) -->
<!-- } -->

<!-- colnames(all.iqv.freq)[1] <- "score" -->

<!-- all.iqv.freq$score <- as.numeric(as.character(all.iqv.freq$score)) -->

<!-- all.iqv.freq -->

<!-- #also for log scale -->
<!-- all.iqv.freq <- all.iqv.freq %>% -->
<!--   mutate(logFreq = log(Freq)) -->

<!-- all.iqv.freq -->
<!-- ``` -->
<!-- ```{r} -->
<!-- ggplot(all.iqv.freq, aes(x=score, y=Freq)) + -->
<!-- #ggplot(all.iqv.freq, aes(x=score, y=logFreq)) + -->
<!--   geom_point(size=0.2) + -->
<!--   geom_segment( aes(x=score, xend=score, y=0, yend=Freq)) + -->
<!--   facet_wrap(~ method) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- #ggplot(all.iqv.freq, aes(x=score, y=Freq)) + -->
<!-- ggplot(all.iqv.freq, aes(x=score, y=logFreq)) + -->
<!--   geom_point(size=0.2) + -->
<!--   geom_segment( aes(x=score, xend=score, y=0, yend=logFreq)) + -->
<!--   facet_wrap(~ method) -->
<!-- ``` -->


#agreement analysis: Entropy

```{r}
#entropy
anno.agreement$entropy <- apply(anno.count,1,entropy,unit = "log2")
```


```{r}
# create max min value for entropy for normalization
library(gtools)

possible_cellstate_with_multi_unknown <- colnames(anno.count)

combinations <- as.data.frame(combinations(length(possible_cellstate_with_multi_unknown),length(tool_names),possible_cellstate_with_multi_unknown,repeats=TRUE))

colnames(combinations) <- tool_names
rownames(combinations) <- 1:nrow(combinations)

# Convert to data.table
combinations <- setDT(rownames_to_column(combinations,var = "cellname"))

# Melt the data.table to long format
anno_long <- melt(combinations, id.vars = "cellname", variable.name = "tool", value.name = "cellstate")


combinations <- dcast(anno_long, cellname ~ cellstate, fun.aggregate = length)

combinations[is.na(combinations)] <- 0

combinations <- column_to_rownames(combinations,var = "cellname")

rm(anno_long)


combinations.entropy <- apply(combinations,1,entropy,unit = "log2")

combinations_max <- max(combinations.entropy)
combinations_min <- min(combinations.entropy)

#combinations.entropy.norm <- (combinations.entropy - combinations_min) / (combinations_max - combinations_min)
anno.agreement$entropy.norm <- (anno.agreement$entropy - combinations_min) / (combinations_max - combinations_min)
anno.agreement$agreement <- 1- anno.agreement$entropy.norm
```
#(archive) agrement analysis:pick best tool combination (now is Fleiss kappa **cannot do it per cell) -->
<!-- ```{r} -->

<!-- #this code is for  -->
<!-- library(foreach) -->
<!-- library(doParallel) -->
<!-- library(irr) -->

<!-- anno_subtools <- anno -->

<!-- col_names <- names(anno_subtools) -->



<!-- anno_subtools[] <- lapply(seq_along(anno_subtools), function(i) { -->
<!--   ifelse(anno_subtools[[i]] == "unknown", paste("unknown", i, sep = "_"), anno_subtools[[i]]) -->
<!-- }) -->


<!-- names(anno_subtools) <- col_names -->


<!-- tool_names <- colnames(anno_subtools) -->
<!-- max_num_of_tools <- length(tool_names) -->

<!-- numCores <- detectCores() - 5 -->
<!-- registerDoParallel(numCores) -->

<!-- # Initialize dataframe with columns for kappa and each tool -->
<!-- column_names <- c("Kappa", tool_names) -->
<!-- results <- data.frame(matrix(ncol = max_num_of_tools + 1, nrow = 0)) -->


<!-- # Perform the analysis -->
<!-- results <- foreach(i = 2:max_num_of_tools, .combine = rbind) %:% -->
<!--   foreach(comb = iter(combn(tool_names, i, simplify = FALSE)), .combine = rbind) %dopar% { -->
<!--     kappa_val <- calculate_kappa_for_combination(anno_subtools, comb) -->
<!--     # Initialize a row with zeros for each tool -->
<!--     tool_presence <- rep(0, max_num_of_tools) -->
<!--     # Set 1 for tools present in the combination -->
<!--     tool_presence[which(tool_names %in% comb)] <- 1 -->
<!--     # Combine kappa value with tool presence -->
<!--     data.frame(Kappa = kappa_val, t(tool_presence)) -->
<!--   } -->

<!-- stopImplicitCluster() -->
<!-- colnames(results) <- column_names -->
<!-- # Extracting the best combination based on the highest kappa value -->
<!-- best_combination <- results[which.max(results$Kappa), ] -->
<!-- results -->
<!-- ``` -->


<!-- ```{r} -->
<!-- library(ggplot2) -->
<!-- results_sorted <- results[order(results$Kappa, decreasing = TRUE), ] -->
<!-- rownames(results_sorted) <- NULL -->


<!-- # Assuming your tool columns are everything except the first (Kappa) and last (NumOfTools) -->
<!-- tool_columns <- 2:(ncol(results_sorted)) -->

<!-- # Convert each row to a binary string -->
<!-- results_sorted$BinaryCode <- as.factor(apply(results_sorted[, tool_columns], 1, function(x) paste(x, collapse = ""))) -->

<!-- results_sorted$BinaryCode <- factor(results_sorted$BinaryCode, levels = unique(results_sorted$BinaryCode)) -->

<!-- limits <- 1 -->
<!-- # Lollipop Plot -->
<!-- p_1 <- ggplot(results_sorted, aes(x = BinaryCode, y = Kappa)) + -->
<!--   geom_segment(aes(x = BinaryCode, xend = BinaryCode, y = 0, yend = Kappa), color = "grey") + -->
<!--   geom_point(color = "blue", size = 3, alpha = 0.6) + -->
<!--   scale_y_continuous(limits = c(-limits, limits)) + -->
<!--   coord_flip() + -->
<!--   labs(x = "Tool Combination (Binary Code)", y = "Kappa Value", title = "Tool Combinations Ranked by Kappa Value", subtitle = paste("with unknown?: ", unknown,"; run as whole or each?: ",run,sep = "")) + -->
<!--   theme_minimal() + -->
<!--   theme(axis.text.x = element_text(angle = 90, hjust = 1)) -->

<!-- # Add a legend or annotation for tool names -->
<!-- # Example: Replace this with your actual tool names -->
<!-- tool_names <- colnames(results_sorted[, tool_columns]) -->
<!-- legend_text <- paste(seq_along(tool_names), ": ", tool_names, collapse = "\n") -->
<!-- p_1 <- p_1 + annotate("text", x = 1, y = 0.5, label = legend_text, hjust = 0, vjust = -4, size = 3) -->

<!-- p_1 -->
<!-- ``` -->


<!-- ```{r} -->
<!-- #donor_id wise -->

<!-- library(parallel) -->


<!-- anno_subtools <- anno -->

<!-- col_names <- names(anno_subtools) -->

<!-- anno_subtools[] <- lapply(seq_along(anno_subtools), function(i) { -->
<!--   ifelse(anno_subtools[[i]] == "unknown", paste("unknown", i, sep = "_"), anno_subtools[[i]]) -->
<!-- }) -->
<!-- names(anno_subtools) <- col_names -->


<!-- n_tool <- ncol(anno_subtools) -->
<!-- #n_tool <- 4 -->
<!-- anno_meta <- (merge(anno_subtools,gbm.meta,by = "row.names")) -->

<!-- calculate_kappa_for_donor <- function(donor_id, data,n_tool) { -->
<!--   # Correctly subset the data for the specific donor_id -->
<!--   subset_data <- data[data$donor_id == donor_id, 2:(n_tool +1)] #not include the first column as it is the rowname -->
<!--   # Calculate Fleiss' Kappa -->
<!--   kappa_result <- kappam.fleiss(subset_data) -->
<!--   return(kappa_result$value) # Returning just the Kappa value -->
<!-- } -->
<!-- # List of unique donor IDs -->
<!-- donor_ids <- as.list(unique(anno_meta$donor_id)) -->

<!-- # Parallel computation of kappa values -->
<!-- kappa_values <- mclapply(donor_ids, function(id) calculate_kappa_for_donor(id, anno_meta,n_tool), mc.cores = detectCores() - 1) -->

<!-- # Combine the results into a named list or another preferred format -->
<!-- names(kappa_values) <- donor_ids -->

<!-- kappa_values_df <- data.frame(kappa_value = t(as.data.frame(kappa_values))) -->
<!-- kappa_values_df -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(ggplot2) -->

<!-- # Ensure kappa_values_df is in the correct format with donor_id and kappa_value -->
<!-- kappa_values_df$donor_id <- rownames(kappa_values_df) -->

<!-- # Convert donor_id to a factor and reorder its levels based on kappa_value -->
<!-- kappa_values_df$donor_id <- factor(kappa_values_df$donor_id, levels = kappa_values_df$donor_id[order(kappa_values_df$kappa_value, decreasing = TRUE)]) -->

<!-- limits <- 0.5 -->
<!-- # Lollipop Plot -->
<!-- ggplot(kappa_values_df, aes(x = donor_id, y = kappa_value)) + -->
<!--   geom_segment(aes(x = donor_id, xend = donor_id, y = 0, yend = kappa_value), color = "grey") + -->
<!--   geom_point(color = "blue", size = 3, alpha = 0.6) + -->
<!--   scale_y_continuous(limits = c(-limits, limits)) + -->
<!--   coord_flip() + -->
<!--   labs(x = "Donor ID", y = "Kappa Value", title = "Kappa Values by Donor ID", subtitle = paste("with unknown?: ", unknown,"; run as whole or each?: ",run,sep = "")) + -->
<!--   theme(axis.text.x = element_text(angle = 90, hjust = 1)) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- library(parallel) -->
<!-- library(foreach) -->
<!-- library(doParallel) -->

<!-- #donor wise with combination -->


<!-- anno_subtools <- anno -->

<!-- col_names <- names(anno_subtools) -->

<!-- anno_subtools[] <- lapply(seq_along(anno_subtools), function(i) { -->
<!--   ifelse(anno_subtools[[i]] == "unknown", paste("unknown", i, sep = "_"), anno_subtools[[i]]) -->
<!-- }) -->
<!-- names(anno_subtools) <- col_names -->

<!-- # Assuming anno is already defined -->
<!-- anno_meta <- merge(anno_subtools, gbm.meta, by = "row.names") -->





<!-- tool_names <- colnames(anno[,1:4]) -->
<!-- max_num_of_tools <- length(tool_names) -->

<!-- # Function to calculate kappa for a specific donor and combination of tools -->
<!-- calculate_kappa_for_donor_combination <- function(donor_id, tools, data) { -->
<!--   subset_data <- data[data$donor_id == donor_id, tools] -->
<!--   kappa_result <- kappam.fleiss(subset_data) -->
<!--   return(kappa_result$value) -->
<!-- } -->

<!-- # List of unique donor IDs -->
<!-- donor_ids <- unique(anno_meta$donor_id) -->

<!-- # Register Parallel Backend -->
<!-- numCores <- detectCores() - 1 -->
<!-- registerDoParallel(numCores) -->

<!-- # Perform the analysis for each donor -->
<!-- results_all <- foreach(donor_id = donor_ids, .combine = rbind) %do% { -->
<!--   foreach(i = 2:max_num_of_tools, .combine = rbind) %:% -->
<!--     foreach(comb = iter(combn(tool_names, i, simplify = FALSE)), .combine = rbind) %dopar% { -->
<!--       kappa_val <- calculate_kappa_for_donor_combination(donor_id, comb, anno_meta) -->
<!--       # Initialize a row with zeros for each tool -->
<!--       tool_presence <- rep(0, max_num_of_tools) -->
<!--       # Set 1 for tools present in the combination -->
<!--       tool_presence[which(tool_names %in% comb)] <- 1 -->
<!--       # Combine kappa value with tool presence and donor_id -->
<!--       data.frame(DonorID = donor_id, Kappa = kappa_val, t(tool_presence)) -->
<!--     } -->
<!-- } -->

<!-- stopImplicitCluster() -->

<!-- # Setting the column names -->
<!-- column_names <- c("DonorID", "Kappa", tool_names) -->
<!-- colnames(results_all) <- column_names -->

<!-- # View the results -->
<!-- results_all -->

<!-- ``` -->


<!-- ```{r} -->
<!-- # Calculate the mean (or another aggregate measure) of Kappa for each tool combination -->
<!-- library(dplyr) -->
<!-- aggregated_results <- results_all %>% -->
<!--   group_by_at(vars(-DonorID, -Kappa)) %>% -->
<!--   summarize(MeanKappa = mean(Kappa, na.rm = TRUE)) %>% -->
<!--   arrange(desc(MeanKappa)) %>% -->
<!--   ungroup -->

<!-- library(dplyr) -->
<!-- library(ggplot2) -->

<!-- # Prepare the data -->
<!-- aggregated_results$BinaryCode <- apply(aggregated_results[,1:4], 1, function(x) { -->
<!--   paste0(x, collapse = "") -->
<!-- }) -->

<!-- # Consider taking the top N combinations for a clearer plot -->


<!-- # # Bar Plot -->
<!-- # ggplot(aggregated_results, aes(x =BinaryCode, y = MeanKappa)) + -->
<!-- #   geom_bar(stat = "identity", fill = "steelblue") + -->
<!-- #   coord_flip() +  # Flips the axes for better readability of combination names -->
<!-- #   labs(x = "Tool Combination", y = "Mean Kappa Value", title = "Top Tool Combinations Across Donors") + -->
<!-- #   theme_minimal() + -->
<!-- #   theme(axis.text.x = element_text(angle = 45, hjust = 1)) -->


<!-- aggregated_results$BinaryCode <- factor(aggregated_results$BinaryCode, levels = unique(results_sorted$BinaryCode)) -->

<!-- limits <- 1 -->
<!-- # Lollipop Plot -->
<!-- p_2 <- ggplot(aggregated_results, aes(x = BinaryCode, y = MeanKappa)) + -->
<!--   geom_segment(aes(x = BinaryCode, xend = BinaryCode, y = 0, yend = MeanKappa), color = "grey") + -->
<!--   geom_point(color = "blue", size = 3, alpha = 0.6) + -->
<!--   scale_y_continuous(limits = c(-limits, limits)) + -->
<!--   coord_flip() + -->
<!--   labs(x = "Tool Combination (Binary Code)", y = "Kappa Value", title = "Tool Combinations Ranked by Kappa Value",subtitle =  paste( "unweighted by cell numbers\n ","with unknown?: ", unknown,"; run as whole or each?: ",run,sep = "")  ) + -->
<!--   theme_minimal() + -->
<!--   theme(axis.text.x = element_text(angle = 90, hjust = 1)) -->
<!-- # Add a legend or annotation for tool names -->
<!-- # Example: Replace this with your actual tool names -->
<!-- tool_names <- colnames(results_sorted[, tool_columns]) -->
<!-- legend_text <- paste(seq_along(tool_names), ": ", tool_names, collapse = "\n") -->

<!-- p_2 <- p_2 + annotate("text", x = 1, y = 0.5, label = legend_text, hjust = 0, vjust = -4, size = 3) -->

<!-- ``` -->
<!-- ```{r} -->
<!-- library(patchwork) -->
<!-- p_1 + p_2 -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Assuming 'results_all' is your dataframe -->
<!-- # Convert donor ID to a factor for better plotting -->
<!-- results_all$DonorID <- as.factor(results_all$DonorID) -->

<!-- # Box Plot -->
<!-- ggplot(results_all, aes(x = DonorID, y = Kappa)) + -->
<!--   geom_boxplot() + -->
<!--   labs(x = "Donor ID", y = "Kappa Value", title = "Distribution of Kappa Values Across Donors") + -->
<!--   theme_minimal() + -->
<!--   theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x labels for better readability -->
<!-- ``` -->











#calculate all stat




```{r}
##calculate score

#convert wide to long
anno_wide <- as.data.table(anno,keep.rownames = TRUE)
anno_score_long <- melt(anno_wide, id.vars = "rn", variable.name = "tools", value.name = "cellstates")

#count the calling from each tool into cellstate
anno_score_long <- anno_score_long[,c(1,3)]
anno_score_long[,binary := 1]
anno_score <- dcast(anno_score_long,formula = rn ~cellstates ,value.var = "binary")


#calculate proportion of unknown
anno_score[,unknown := unknown/ncol(anno)]

#calculate confidence score
anno_score[, confidence := apply(.SD, 1, max)/ncol(anno), .SDcols = 2:4]

#split unknown and confidence temporaly 
anno_score_unknown <- anno_score[,.(rn,unknown,confidence)]
anno_score <-  anno_score[,..possible_cellstate,with = FALSE]



#order the score and rank
anno_score[, paste0("Rank_",possible_cellstate) :=
  as.data.table(t(apply(.SD, 1, function(x) frank(-x, ties.method = "dense")))),
  .SDcols = possible_cellstate]
anno_score <- cbind(anno_score_unknown,anno_score)


# Assign Tie condition
rank_columns <- grep("^Rank_", names(anno_score), value = TRUE)
anno_score[, Tie := rowSums(.SD == 1) > 1, .SDcols = rank_columns]

#stochastic consensus base on the number of call on that cell
pick_cellstate_stocastic <- function(row) {
  probs <- row / sum(row)  # Calculate probabilities based on count
  selected_cellstate <- sample(names(row), size = 1, prob = probs)
  return(selected_cellstate)
}
anno_score[, stochastic_consensus := apply(.SD, 1, pick_cellstate_stocastic), .SDcols = possible_cellstate]
anno_score$stochastic_consensus <- as.factor(anno_score$stochastic_consensus)

consensus_with_stochastic_of_tie_fn <- function(row) {
  max_confidence <- max(row)
  max_diseases <- names(row[row == max_confidence])
  
  if (length(max_diseases) == 1) {
    # Deterministic selection when there's no tie
    selected_disease <- max_diseases
  } else {
    # Stochastic selection when there is a tie
    selected_disease <- sample(max_diseases, size = 1)
  }
  
  return(selected_disease)
}
anno_score[, consensus_with_stochastic_of_tie := apply(.SD, 1, consensus_with_stochastic_of_tie_fn), .SDcols = possible_cellstate]
anno_score$consensus_with_stochastic_of_tie <- as.factor(anno_score$consensus_with_stochastic_of_tie)

anno_score
```
```{r}

thresholds <- 0.5



# #Option 0
# anno_score[,consensus := NA_character_] #create consensus column
# anno_score[Tie == FALSE, consensus := colnames(.SD)[apply(.SD, 1, which.max)], .SDcols = possible_cellstate]
# anno_score[confidence < thresholds,consensus:= "unknown"]
# anno_score[Tie == TRUE, consensus:= "tie"] #assign unknown to Tie condition
# anno_score[unknown == 1, consensus:= "unassigned"] #assign unknown to Tie condition

#Option 1: 1. call unknown only when all tool are unknown 2. stocastic tie
anno_score[,consensus := consensus_with_stochastic_of_tie] #create consensus column
anno_score[unknown == 1, consensus:= "unassign"]
#anno_score[confidence < thresholds,consensus:= "unassign"] dont need this because we already use stocastic



anno_score$consensus <- as.factor(anno_score$consensus)



table(anno_score$consensus)
```
#combind all score
```{r}
#gbm.meta <- read.csv("output/gbm_meta.csv", row.names = 1)

# Import metadata
anno.agreement.chosen <- rownames_to_column(anno.agreement,var = "rn")
anno.agreement.chosen <- anno.agreement.chosen %>% select(rn,agreement)
anno.all <- merge(anno_score,anno.agreement.chosen,
                  by = "rn")

anno_score
fwrite(anno.all, file = paste("output/annotation/annotation",merge,run,unknown,".csv",sep = "_"))


```


```{r}
#shorter verion

chosen_info <- c("rn","consensus","confidence","agreement","unknown")
anno.all.short <- anno.all[,chosen_info,with = FALSE]
anno.all.short
fwrite(anno.all.short, file = paste("output/annotation/annotation_short",merge,run,unknown,".csv",sep = "_"))
```




